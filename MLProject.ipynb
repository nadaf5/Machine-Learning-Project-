{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Mental Health in Tech Survey**"
      ],
      "metadata": {
        "id": "OvWG6WJFSKlv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries"
      ],
      "metadata": {
        "id": "-CqX_ZO2B3-W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# English: Import all the libraries needed for data analysis and ML.\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score\n",
        "import kagglehub\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "import scipy.cluster.hierarchy as sch\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import KFold\n"
      ],
      "metadata": {
        "id": "IlL-vJxHBwUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the Dataset\n"
      ],
      "metadata": {
        "id": "V2_f-7GvCABw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0ffj-g8rv8e"
      },
      "outputs": [],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"osmi/mental-health-in-tech-survey\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)\n",
        "\n",
        "# Download dataset\n",
        "path = kagglehub.dataset_download(\"osmi/mental-health-in-tech-survey\")\n",
        "print(\"Path to dataset files:\", path)\n",
        "\n",
        "# Load dataset after download\n",
        "df = pd.read_csv(path + \"/survey.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Explore the Dataset"
      ],
      "metadata": {
        "id": "D7OKaV8dCQ5D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.1"
      ],
      "metadata": {
        "id": "07dtvSbWCYdS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head())"
      ],
      "metadata": {
        "id": "dYLBd3djtosv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.2"
      ],
      "metadata": {
        "id": "gETuVcQqCeC8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.describe())"
      ],
      "metadata": {
        "id": "YiiVlBSO9vWF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.3"
      ],
      "metadata": {
        "id": "wPv6YVqiCh70"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "Y_Ysrv9OwQcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.4"
      ],
      "metadata": {
        "id": "0Tr0MURXCptE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values\n",
        "missing_values = df.isnull().sum()\n",
        "print(missing_values)\n",
        "\n",
        "# Check for duplicates\n",
        "print(df.duplicated().sum())\n",
        "\n",
        "# Remove duplicates\n",
        "df = df.drop_duplicates()\n"
      ],
      "metadata": {
        "id": "1w1lLACG92mf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.duplicated().sum())  # Check for duplicates\n",
        "df = df.drop_duplicates()  # Drop duplicates if any"
      ],
      "metadata": {
        "id": "_TldVQlqwdmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "-HOmVXdLwi7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Visualization"
      ],
      "metadata": {
        "id": "vxibvCztCy7A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# English: Visualize the distribution of numerical features (e.g., Age).\n",
        "def plot_histogram(df, column_name):\n",
        "    \"\"\"\n",
        "    Plots a histogram for a given column in a DataFrame to inspect the distribution and potential outliers.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    df[column_name].hist(bins=20, edgecolor='black')\n",
        "    plt.title(f\"Histogram of {column_name}\")\n",
        "    plt.xlabel(column_name)\n",
        "    plt.ylabel(\"Frequency\")\n",
        "    plt.show()\n",
        "\n",
        "# Example usage:\n",
        "plot_histogram(df, 'Age')"
      ],
      "metadata": {
        "id": "tP6e7r5kwrl_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A histogram of the â€˜Ageâ€™ variable indicates a right-skewed distribution, suggesting potential outliers that may need to be handled during preprocessing."
      ],
      "metadata": {
        "id": "UxVC8-NH-Q9c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "WOA1hx2fDDsm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# English: Prepare data for machine learning â€” select features, handle missing values, and scale data.\n",
        "# Arabic: ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù‚Ø¨Ù„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ØŒ Ø¨Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ù‡Ù…Ø© ÙˆÙ…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø© ÙˆØªÙˆØ­ÙŠØ¯ Ø§Ù„Ù…Ù‚ÙŠØ§Ø³.\n",
        "\n",
        "# Drop rows with missing 'Age' or 'Gender' for simplicity\n",
        "df = df.dropna(subset=['Age', 'Gender'])\n",
        "\n",
        "# Example feature selection (adjust columns as needed)\n",
        "X = df[['Age']]  # Features\n",
        "y = (df['treatment'] == 'Yes').astype(int)  # Target variable (1 = needs treatment)\n",
        "\n",
        "# Split into train/test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the data (important for Logistic Regression)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "Spwy35vrDHi3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (Updated): Data Preprocessing with Multiple Features"
      ],
      "metadata": {
        "id": "drW_zre_EyIO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# English: Select multiple meaningful features to help the model learn better patterns.\n",
        "# Arabic: Ø§Ø®ØªÙŠØ§Ø± Ø£ÙƒØ«Ø± Ù…Ù† Ø¹Ù…ÙˆØ¯ (Feature) Ø­ØªÙ‰ ÙŠØ³ØªØ·ÙŠØ¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ØªØ¹Ù„Ù… Ø§Ù„Ø¹Ù„Ø§Ù‚Ø§Øª Ø¨Ø´ÙƒÙ„ Ø£Ø¯Ù‚.\n",
        "\n",
        "# Remove rows with missing key information\n",
        "df = df.dropna(subset=['Age', 'Gender', 'work_interfere', 'family_history', 'remote_work'])\n",
        "\n",
        "# Handle categorical values (convert text to numbers)\n",
        "df_encoded = pd.get_dummies(df[['Age', 'Gender', 'work_interfere', 'family_history', 'remote_work']], drop_first=True)\n",
        "\n",
        "# Define features (X) and target (y)\n",
        "X = df_encoded\n",
        "y = (df['treatment'] == 'Yes').astype(int)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the numerical features\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "wHTV6yssE6S8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define the target variable and prepare features"
      ],
      "metadata": {
        "id": "qxn0tdwv8Ien"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the target column \"treatment\" (Yes/No)\n",
        "\n",
        "target = 'treatment'\n",
        "\n",
        "# Drop the target from the features\n",
        "X = df.drop(columns=[target])\n",
        "y = df[target]\n",
        "\n",
        "print(\"Shape of features:\", X.shape)\n",
        "print(\"Shape of target:\", y.shape)"
      ],
      "metadata": {
        "id": "BEI2w7KixCdP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encode categorical variables"
      ],
      "metadata": {
        "id": "A1sQXrfU-aSG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Arabic: Ø¨Ø¹Ø¶ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù†ØµÙˆØµ (Ù…Ø«Ù„ \"Yes\", \"No\", \"Male\", \"Female\")\n",
        "# Ù„Ø°Ù„Ùƒ Ù†Ø­ÙˆÙ„Ù‡Ø§ Ø¥Ù„Ù‰ Ø£Ø±Ù‚Ø§Ù… Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¯ÙˆØ§Ù„ Ø§Ù„Ø¬Ø§Ù‡Ø²Ø© ÙÙŠ pandas.\n",
        "#  Convert categorical columns into numeric format using get_dummies()\n",
        "X = pd.get_dummies(X, drop_first=True)\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoder = LabelEncoder()\n",
        "y = encoder.fit_transform(y)  # Yes -> 1, No -> 0\n",
        "\n",
        "print(\"Encoded target sample:\", y[:5])\n"
      ],
      "metadata": {
        "id": "fT7hG2CM-T3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Split the dataset into training and testing sets\n"
      ],
      "metadata": {
        "id": "DYbDf_im-tzb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Arabic: Ù†Ù‚Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ Ø¬Ø²Ø¦ÙŠÙ† â€” Ø¬Ø²Ø¡ Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆØ¬Ø²Ø¡ Ù„Ø§Ø®ØªØ¨Ø§Ø±Ù‡.\n",
        "# Split data into training (80%) and testing (20%) sets.\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Training data shape:\", X_train.shape)\n",
        "print(\"Testing data shape:\", X_test.shape)"
      ],
      "metadata": {
        "id": "VZLlu_Gb-vPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Normalize the data\n"
      ],
      "metadata": {
        "id": "mscpTgjJ-4fk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Arabic: Ù†Ù‚ÙˆÙ… Ø¨ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„ØªÙƒÙˆÙ† Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù‚ÙŠÙ… ÙÙŠ Ù†ÙØ³ Ø§Ù„Ù†Ø·Ø§Ù‚.\n",
        "# English: Scale the data so that all features have similar ranges.\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "Ilv_QQMl-6qP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the supervised learning model"
      ],
      "metadata": {
        "id": "oGTGFwwN--tE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# English: Train a Logistic Regression model and evaluate it.\n",
        "# Arabic: ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø§Ù†Ø­Ø¯Ø§Ø± Ø§Ù„Ù„ÙˆØ¬Ø³ØªÙŠ ÙˆØªÙ‚ÙŠÙŠÙ… Ø£Ø¯Ø§Ø¦Ù‡.\n",
        "\n",
        "log_model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "log_model.fit(X_train_scaled, y_train)\n",
        "y_pred_log = log_model.predict(X_test_scaled)\n",
        "\n",
        "# Evaluation\n",
        "log_acc = accuracy_score(y_test, y_pred_log)\n",
        "print(\"Logistic Regression Accuracy:\", log_acc)\n",
        "print(\"\\nClassification Report (Logistic Regression):\")\n",
        "print(classification_report(y_test, y_pred_log))"
      ],
      "metadata": {
        "id": "GmFFjuOP_Coi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# English: Train a Random Forest model and evaluate it.\n",
        "# Arabic: ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØºØ§Ø¨Ø© Ø§Ù„Ø¹Ø´ÙˆØ§Ø¦ÙŠØ© ÙˆÙ…Ù‚Ø§Ø±Ù†Ø© Ø£Ø¯Ø§Ø¦Ù‡ Ù…Ø¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø£ÙˆÙ„.\n",
        "\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train_scaled, y_train)\n",
        "y_pred_rf = rf_model.predict(X_test_scaled)\n",
        "\n",
        "rf_acc = accuracy_score(y_test, y_pred_rf)\n",
        "print(\"Random Forest Accuracy:\", rf_acc)\n",
        "print(\"\\nClassification Report (Random Forest):\")\n",
        "print(classification_report(y_test, y_pred_rf))\n"
      ],
      "metadata": {
        "id": "jNvLcF35BExm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Both Models Again"
      ],
      "metadata": {
        "id": "jz2EYqa2FHkZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrain Models with More Features\n",
        "# English: Train both models again using the updated dataset.\n",
        "# Arabic: Ø¥Ø¹Ø§Ø¯Ø© ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ÙŠÙ† Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©.\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "# --- Model 1: Logistic Regression ---\n",
        "log_model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "log_model.fit(X_train_scaled, y_train)\n",
        "y_pred_log = log_model.predict(X_test_scaled)\n",
        "\n",
        "# --- Model 2: Random Forest ---\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train_scaled, y_train)\n",
        "y_pred_rf = rf_model.predict(X_test_scaled)"
      ],
      "metadata": {
        "id": "6OCcKggMFJXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate the model"
      ],
      "metadata": {
        "id": "HaXfrCOh_RND"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# English: Compare the two models based on their performance metrics.\n",
        "# Arabic: Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ÙŠÙ† Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ø£Ø¯Ø§Ø¡.\n",
        "\n",
        "metrics = {\n",
        "    \"Model\": [\"Logistic Regression\", \"Random Forest\"],\n",
        "    \"Accuracy\": [\n",
        "        accuracy_score(y_test, y_pred_log),\n",
        "        accuracy_score(y_test, y_pred_rf)\n",
        "    ],\n",
        "    \"Precision\": [\n",
        "        precision_score(y_test, y_pred_log),\n",
        "        precision_score(y_test, y_pred_rf)\n",
        "    ],\n",
        "    \"Recall\": [\n",
        "        recall_score(y_test, y_pred_log),\n",
        "        recall_score(y_test, y_pred_rf)\n",
        "    ],\n",
        "    \"F1 Score\": [\n",
        "        f1_score(y_test, y_pred_log),\n",
        "        f1_score(y_test, y_pred_rf)\n",
        "    ]\n",
        "}\n",
        "\n",
        "results_df = pd.DataFrame(metrics)\n",
        "display(results_df)\n"
      ],
      "metadata": {
        "id": "144Qy5aC_Uln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compare the Results with more frutres"
      ],
      "metadata": {
        "id": "FFkIc8zsFj1_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ“Š Step 7: Model Comparison\n",
        "# ==========================================================\n",
        "# English: Compare the two models using performance metrics.\n",
        "# Arabic: Ù…Ù‚Ø§Ø±Ù†Ø© Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ÙŠÙ† ÙÙŠ Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©.\n",
        "\n",
        "metrics = {\n",
        "    \"Model\": [\"Logistic Regression\", \"Random Forest\"],\n",
        "    \"Accuracy\": [\n",
        "        accuracy_score(y_test, y_pred_log),\n",
        "        accuracy_score(y_test, y_pred_rf)\n",
        "    ],\n",
        "    \"Precision\": [\n",
        "        precision_score(y_test, y_pred_log),\n",
        "        precision_score(y_test, y_pred_rf)\n",
        "    ],\n",
        "    \"Recall\": [\n",
        "        recall_score(y_test, y_pred_log),\n",
        "        recall_score(y_test, y_pred_rf)\n",
        "    ],\n",
        "    \"F1 Score\": [\n",
        "        f1_score(y_test, y_pred_log),\n",
        "        f1_score(y_test, y_pred_rf)\n",
        "    ]\n",
        "}\n",
        "\n",
        "results_df = pd.DataFrame(metrics)\n",
        "display(results_df)"
      ],
      "metadata": {
        "id": "p-AOZnIuFnPV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualize"
      ],
      "metadata": {
        "id": "tVgVerph_aod"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# English: Visualize and compare model performance using a bar chart.\n",
        "# Arabic: Ø±Ø³Ù… Ø¨ÙŠØ§Ù†ÙŠ Ù„Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø¨ÙŠÙ† Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ÙŠÙ† Ù…Ù† Ø­ÙŠØ« Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ù…Ø®ØªÙ„ÙØ©.\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define metrics and values\n",
        "metrics_names = [\"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"]\n",
        "log_values = [\n",
        "    accuracy_score(y_test, y_pred_log),\n",
        "    precision_score(y_test, y_pred_log),\n",
        "    recall_score(y_test, y_pred_log),\n",
        "    f1_score(y_test, y_pred_log)\n",
        "]\n",
        "rf_values = [\n",
        "    accuracy_score(y_test, y_pred_rf),\n",
        "    precision_score(y_test, y_pred_rf),\n",
        "    recall_score(y_test, y_pred_rf),\n",
        "    f1_score(y_test, y_pred_rf)\n",
        "]\n",
        "\n",
        "# Bar width and positions\n",
        "x = range(len(metrics_names))\n",
        "bar_width = 0.35\n",
        "\n",
        "# Create the plot\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.bar(x, log_values, width=bar_width, label=\"Logistic Regression\", color='skyblue')\n",
        "plt.bar([p + bar_width for p in x], rf_values, width=bar_width, label=\"Random Forest\", color='lightgreen')\n",
        "\n",
        "# Add labels and title\n",
        "plt.xticks([p + bar_width / 2 for p in x], metrics_names)\n",
        "plt.ylabel(\"Score\")\n",
        "plt.title(\"Model Performance Comparison\")\n",
        "plt.legend()\n",
        "\n",
        "# Show grid for clarity\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vrV3o2x7AsKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Logistic Regression model is simpler and works well when the data is linearly separable (meaning, the classes can be divided by a straight line or simple boundary).\n",
        "If the dataset doesnâ€™t have complex relationships between features â€” or if you only use one or two variables (like Age or Gender) â€” Logistic Regression might perform better because it doesnâ€™t overfit."
      ],
      "metadata": {
        "id": "wq7jaBR9GEEC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualization (Reused from before)"
      ],
      "metadata": {
        "id": "MlYr0ODQGM0-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization (Updated Results)\n",
        "\n",
        "metrics_names = [\"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"]\n",
        "log_values = [\n",
        "    accuracy_score(y_test, y_pred_log),\n",
        "    precision_score(y_test, y_pred_log),\n",
        "    recall_score(y_test, y_pred_log),\n",
        "    f1_score(y_test, y_pred_log)\n",
        "]\n",
        "rf_values = [\n",
        "    accuracy_score(y_test, y_pred_rf),\n",
        "    precision_score(y_test, y_pred_rf),\n",
        "    recall_score(y_test, y_pred_rf),\n",
        "    f1_score(y_test, y_pred_rf)\n",
        "]\n",
        "\n",
        "x = range(len(metrics_names))\n",
        "bar_width = 0.35\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.bar(x, log_values, width=bar_width, label=\"Logistic Regression\", color='skyblue')\n",
        "plt.bar([p + bar_width for p in x], rf_values, width=bar_width, label=\"Random Forest\", color='lightgreen')\n",
        "plt.xticks([p + bar_width / 2 for p in x], metrics_names)\n",
        "plt.ylabel(\"Score\")\n",
        "plt.title(\"Model Performance Comparison (After Adding More Features)\")\n",
        "plt.legend()\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TWmnqxb8GPwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After applying both models, Random Forest outperformed Logistic Regression in terms of accuracy and F1 score.\n",
        "This indicates that the dataset contains non-linear relationships between features and the target variable.\n",
        "Therefore, tree-based ensemble methods such as Random Forest are more suitable for this type of data."
      ],
      "metadata": {
        "id": "u5Eg2TV0Gn7m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data preparation\n"
      ],
      "metadata": {
        "id": "XokGaDILI-M8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load dataset again (same data)\n",
        "df = pd.read_csv(\"/kaggle/input/mental-health-in-tech-survey/survey.csv\")\n",
        "\n",
        "# Select relevant numeric and categorical columns\n",
        "selected_columns = ['Age', 'Gender', 'Country', 'self_employed', 'family_history', 'treatment']\n",
        "df = df[selected_columns].copy()\n",
        "\n",
        "# Fill missing values\n",
        "df['self_employed'] = df['self_employed'].fillna('No')\n",
        "df['Age'] = df['Age'].fillna(df['Age'].median())\n",
        "\n",
        "# Label Encoding for categorical variables\n",
        "le = LabelEncoder()\n",
        "for col in ['Gender', 'Country', 'self_employed', 'family_history', 'treatment']:\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "\n",
        "# Scale the data\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(df)\n",
        "\n",
        "# Show first rows\n",
        "print(\"Data is ready for unsupervised learning!\")\n",
        "pd.DataFrame(X_scaled, columns=df.columns).head()"
      ],
      "metadata": {
        "id": "6GhGvg7EJIfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# K-Means Clustering (Model 1)"
      ],
      "metadata": {
        "id": "baJ4DA2xJVPY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Try to find the optimal number of clusters using the Elbow method\n",
        "inertia = []\n",
        "K = range(2, 8)\n",
        "for k in K:\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
        "    kmeans.fit(X_scaled)\n",
        "    inertia.append(kmeans.inertia_)\n",
        "\n",
        "# Plot the Elbow Curve\n",
        "plt.plot(K, inertia, marker='o')\n",
        "plt.title(\"Elbow Method for Optimal K\")\n",
        "plt.xlabel(\"Number of Clusters\")\n",
        "plt.ylabel(\"Inertia\")\n",
        "plt.show()\n",
        "\n",
        "# Train final KMeans with optimal K (letâ€™s assume K=3)\n",
        "kmeans_final = KMeans(n_clusters=3, random_state=42)\n",
        "clusters_kmeans = kmeans_final.fit_predict(X_scaled)\n",
        "\n",
        "# Evaluate using Silhouette Score\n",
        "score_kmeans = silhouette_score(X_scaled, clusters_kmeans)\n",
        "print(f\"K-Means Silhouette Score: {score_kmeans:.3f}\")"
      ],
      "metadata": {
        "id": "zPh4fNZDJZE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hierarchical Clustering (Model 2)"
      ],
      "metadata": {
        "id": "8tlJBiZnJlc5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Plot Dendrogram to visualize the cluster hierarchy\n",
        "plt.figure(figsize=(10, 5))\n",
        "dendrogram = sch.dendrogram(sch.linkage(X_scaled, method='ward'))\n",
        "plt.title(\"Dendrogram for Hierarchical Clustering\")\n",
        "plt.xlabel(\"Samples\")\n",
        "plt.ylabel(\"Euclidean Distance\")\n",
        "plt.show()\n",
        "\n",
        "## Fit Agglomerative Clustering with 3 clusters (updated parameter name)\n",
        "hc = AgglomerativeClustering(n_clusters=3, metric='euclidean', linkage='ward')\n",
        "clusters_hc = hc.fit_predict(X_scaled)\n",
        "\n",
        "# Evaluate using Silhouette Score\n",
        "score_hc = silhouette_score(X_scaled, clusters_hc)\n",
        "print(f\"Hierarchical Clustering Silhouette Score: {score_hc:.3f}\")"
      ],
      "metadata": {
        "id": "SwdlWcnyJske"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comparison Table"
      ],
      "metadata": {
        "id": "kDWuaLUOKlQ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "comparison_df = pd.DataFrame({\n",
        "    'Model': ['K-Means', 'Hierarchical'],\n",
        "    'Silhouette Score': [score_kmeans, score_hc],\n",
        "    'Comments': ['Simple & fast clustering', 'More detailed structure']\n",
        "})\n",
        "\n",
        "print(\"\\nUnsupervised Model Comparison:\")\n",
        "display(comparison_df)\n"
      ],
      "metadata": {
        "id": "HkIxc0H-Kp_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Reduce the data to 2 dimensions for visualization\n",
        "pca = PCA(n_components=2)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "# Create a DataFrame for easier plotting\n",
        "pca_df = pd.DataFrame(data=X_pca, columns=['PCA1', 'PCA2'])\n",
        "pca_df['KMeans_Cluster'] = clusters_kmeans\n",
        "pca_df['HC_Cluster'] = clusters_hc\n",
        "\n",
        "# Plot K-Means Clusters\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.scatter(pca_df['PCA1'], pca_df['PCA2'], c=pca_df['KMeans_Cluster'], cmap='Set1')\n",
        "plt.title(\"K-Means Clusters Visualization (PCA Reduced)\")\n",
        "plt.xlabel(\"Principal Component 1\")\n",
        "plt.ylabel(\"Principal Component 2\")\n",
        "plt.show()\n",
        "\n",
        "# Plot Hierarchical Clusters\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.scatter(pca_df['PCA1'], pca_df['PCA2'], c=pca_df['HC_Cluster'], cmap='Set2')\n",
        "plt.title(\"Hierarchical Clusters Visualization (PCA Reduced)\")\n",
        "plt.xlabel(\"Principal Component 1\")\n",
        "plt.ylabel(\"Principal Component 2\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "0x-UViTXK6lh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 6: CLUSTERING CROSS-VALIDATION (OPTIONAL)\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# Define a basic K-Fold approach to check stability of Silhouette score\n",
        "kf = KFold(n_splits=3, shuffle=True, random_state=42)\n",
        "scores = []\n",
        "\n",
        "for train_index, test_index in kf.split(X_scaled):\n",
        "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
        "    model = KMeans(n_clusters=3, random_state=42)\n",
        "    labels = model.fit_predict(X_train)\n",
        "    score = silhouette_score(X_train, labels)\n",
        "    scores.append(score)\n",
        "\n",
        "print(f\"Cross-Validation Silhouette Scores: {np.round(scores, 3)}\")\n",
        "print(f\"Average Silhouette Score across folds: {np.mean(scores):.3f}\")\n"
      ],
      "metadata": {
        "id": "-nEs3TFjLLBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "# Combine supervised + unsupervised results\n",
        "data = {\n",
        "    \"Model\": [\"Logistic Regression\", \"Random Forest\", \"K-Means\", \"Hierarchical\"],\n",
        "    \"Score\": [0.76, 0.79, 0.325, 0.35],\n",
        "    \"Metric\": [\"Accuracy\", \"Accuracy\", \"Silhouette\", \"Silhouette\"],\n",
        "    \"Type\": [\"Supervised\", \"Supervised\", \"Unsupervised\", \"Unsupervised\"]\n",
        "}\n",
        "\n",
        "results = pd.DataFrame(data)\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "sns.barplot(x=\"Model\", y=\"Score\", hue=\"Type\", data=results, palette=\"viridis\")\n",
        "\n",
        "plt.title(\"Combined Model Comparison (Supervised vs. Unsupervised)\")\n",
        "plt.ylabel(\"Score\")\n",
        "plt.ylim(0,1)\n",
        "plt.xticks(rotation=20)\n",
        "plt.legend(title=\"Model Type\")\n",
        "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.6)\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "Bzwzsf6JlkAH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Both clustering models identified distinct groups within the dataset.\n",
        "However, Hierarchical Clustering achieved a higher Silhouette Score, suggesting it better captured the relationships among the participants"
      ],
      "metadata": {
        "id": "xqWMVrFpK6K7"
      }
    }
  ]
}